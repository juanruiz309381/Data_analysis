{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 5: Modelo Predictivo con Machine Learning\n",
    "\n",
    "**Proyecto:** An√°lisis de Deserci√≥n Educativa en Colombia\n",
    "\n",
    "**Objetivos:**\n",
    "1. Preparar datos para modelado predictivo\n",
    "2. Realizar feature engineering\n",
    "3. Entrenar y comparar m√∫ltiples modelos\n",
    "4. Optimizar el mejor modelo\n",
    "5. Evaluar con m√©tricas apropiadas\n",
    "6. Interpretar predicciones (SHAP)\n",
    "7. Guardar modelo para producci√≥n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Balanceo de clases\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "os.makedirs('../src/models', exist_ok=True)\n",
    "os.makedirs('../reports/figures', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "df = pd.read_csv('../data/processed/desercion_academica_clean.csv')\n",
    "\n",
    "print(f\"Dataset cargado: {len(df):,} registros\")\n",
    "print(f\"Columnas: {df.shape[1]}\")\n",
    "print(f\"\\nColumnas disponibles: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset para ML\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Variable objetivo: todos son desertores en este dataset, necesitamos crear variable sint√©tica\n",
    "# o usar el score de riesgo del BI\n",
    "# Para este ejercicio, usaremos caracter√≠sticas para predecir tipo de deserci√≥n\n",
    "# o crearemos clases basadas en caracter√≠sticas\n",
    "\n",
    "# Opci√≥n: Clasificar por nivel de riesgo alto/bajo\n",
    "# Calcular score basado en m√∫ltiples factores\n",
    "def calcular_score_riesgo_ml(row):\n",
    "    score = 0\n",
    "    if 'estrato_num' in row and not pd.isna(row['estrato_num']):\n",
    "        if row['estrato_num'] in [1, 2]: score += 30\n",
    "        elif row['estrato_num'] in [3, 4]: score += 15\n",
    "    if 'modalidad' in row and row['modalidad'] in ['VIRTUAL', 'DISTANCIA']: score += 25\n",
    "    if 'edad' in row and not pd.isna(row['edad']):\n",
    "        if row['edad'] < 18 or row['edad'] > 30: score += 20\n",
    "    if 'jornada' in row and 'NOCTURNA' in str(row['jornada']).upper(): score += 15\n",
    "    if 'genero' in row and row['genero'] == 'M': score += 5\n",
    "    return min(score, 100)\n",
    "\n",
    "df_ml['score_riesgo'] = df_ml.apply(calcular_score_riesgo_ml, axis=1)\n",
    "df_ml['alto_riesgo'] = (df_ml['score_riesgo'] >= 50).astype(int)\n",
    "\n",
    "print(f\"\\nDistribuci√≥n de clase objetivo:\")\n",
    "print(df_ml['alto_riesgo'].value_counts())\n",
    "print(f\"\\nPorcentaje de alto riesgo: {df_ml['alto_riesgo'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar y crear features\n",
    "features_numericas = []\n",
    "features_categoricas = []\n",
    "\n",
    "# Features num√©ricas\n",
    "if 'edad' in df_ml.columns:\n",
    "    features_numericas.append('edad')\n",
    "if 'estrato_num' in df_ml.columns:\n",
    "    df_ml['estrato_num'] = df_ml['estrato_num'].fillna(df_ml['estrato_num'].median())\n",
    "    features_numericas.append('estrato_num')\n",
    "if 'periodo_a√±o' in df_ml.columns:\n",
    "    features_numericas.append('periodo_a√±o')\n",
    "if 'periodo_semestre' in df_ml.columns:\n",
    "    features_numericas.append('periodo_semestre')\n",
    "\n",
    "# Features categ√≥ricas\n",
    "if 'genero' in df_ml.columns:\n",
    "    features_categoricas.append('genero')\n",
    "if 'modalidad' in df_ml.columns:\n",
    "    features_categoricas.append('modalidad')\n",
    "if 'jornada' in df_ml.columns:\n",
    "    features_categoricas.append('jornada')\n",
    "\n",
    "# Features derivadas\n",
    "if 'edad' in df_ml.columns:\n",
    "    df_ml['edad_fuera_rango'] = ((df_ml['edad'] < 18) | (df_ml['edad'] > 30)).astype(int)\n",
    "    features_numericas.append('edad_fuera_rango')\n",
    "\n",
    "if 'modalidad' in df_ml.columns:\n",
    "    df_ml['es_virtual'] = df_ml['modalidad'].isin(['VIRTUAL', 'DISTANCIA']).astype(int)\n",
    "    features_numericas.append('es_virtual')\n",
    "\n",
    "if 'estrato_num' in df_ml.columns:\n",
    "    df_ml['estrato_bajo'] = (df_ml['estrato_num'] <= 2).astype(int)\n",
    "    features_numericas.append('estrato_bajo')\n",
    "\n",
    "print(f\"\\nFeatures num√©ricas: {features_numericas}\")\n",
    "print(f\"Features categ√≥ricas: {features_categoricas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variables categ√≥ricas\n",
    "df_encoded = df_ml.copy()\n",
    "\n",
    "# One-Hot Encoding\n",
    "for col in features_categoricas:\n",
    "    if col in df_encoded.columns:\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=True)\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "\n",
    "# Listar todas las features finales\n",
    "features_finales = features_numericas.copy()\n",
    "for col in features_categoricas:\n",
    "    dummy_cols = [c for c in df_encoded.columns if c.startswith(col + '_')]\n",
    "    features_finales.extend(dummy_cols)\n",
    "\n",
    "print(f\"\\nTotal features: {len(features_finales)}\")\n",
    "print(f\"Features: {features_finales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparaci√≥n de Datos para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X e y\n",
    "X = df_encoded[features_finales].fillna(0)\n",
    "y = df_encoded['alto_riesgo']\n",
    "\n",
    "print(f\"Shape X: {X.shape}\")\n",
    "print(f\"Shape y: {y.shape}\")\n",
    "print(f\"\\nDistribuci√≥n de clases:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nBalance: {y.value_counts(normalize=True)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úì Datos escalados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balanceo\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nDatos despu√©s de SMOTE:\")\n",
    "print(f\"Train original: {len(X_train)}\")\n",
    "print(f\"Train balanceado: {len(X_train_balanced)}\")\n",
    "print(f\"\\nDistribuci√≥n despu√©s SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de evaluaci√≥n\n",
    "def evaluar_modelo(modelo, X_test, y_test, nombre):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_pred_proba = modelo.predict_proba(X_test)[:, 1] if hasattr(modelo, 'predict_proba') else y_pred\n",
    "    \n",
    "    return {\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "print(\"Funci√≥n de evaluaci√≥n definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar m√∫ltiples modelos\n",
    "modelos = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, max_depth=10, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENTRENANDO MODELOS...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando {nombre}...\")\n",
    "    modelo.fit(X_train_balanced, y_train_balanced)\n",
    "    resultado = evaluar_modelo(modelo, X_test_scaled, y_test, nombre)\n",
    "    resultados.append(resultado)\n",
    "    print(f\"‚úì F1-Score: {resultado['F1-Score']:.4f}\")\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "df_resultados = pd.DataFrame(resultados).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTADOS DE TODOS LOS MODELOS\")\n",
    "print(\"=\" * 70)\n",
    "print(df_resultados.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metricas = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "for idx, metrica in enumerate(metricas):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    df_sorted = df_resultados.sort_values(metrica, ascending=True)\n",
    "    y_pos = np.arange(len(df_sorted))\n",
    "    bars = ax.barh(y_pos, df_sorted[metrica], alpha=0.8)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(df_sorted['Modelo'])\n",
    "    ax.set_xlabel(metrica)\n",
    "    ax.set_title(f'Comparaci√≥n de Modelos - {metrica}', fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Color del mejor\n",
    "    best_idx = df_sorted[metrica].idxmax()\n",
    "    bars[list(df_sorted.index).index(best_idx)].set_color('green')\n",
    "    bars[list(df_sorted.index).index(best_idx)].set_alpha(1.0)\n",
    "    \n",
    "    # A√±adir valores\n",
    "    for i, v in enumerate(df_sorted[metrica]):\n",
    "        ax.text(v + 0.005, i, f'{v:.3f}', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/ml_comparacion_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: reports/figures/ml_comparacion_modelos.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecci√≥n y Optimizaci√≥n del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar mejor modelo\n",
    "mejor_modelo_nombre = df_resultados.iloc[0]['Modelo']\n",
    "mejor_f1 = df_resultados.iloc[0]['F1-Score']\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {mejor_modelo_nombre}\")\n",
    "print(f\"   F1-Score: {mejor_f1:.4f}\")\n",
    "\n",
    "# Reentrenar mejor modelo\n",
    "if 'Random Forest' in mejor_modelo_nombre:\n",
    "    mejor_modelo = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "elif 'XGBoost' in mejor_modelo_nombre:\n",
    "    mejor_modelo = xgb.XGBClassifier(n_estimators=200, max_depth=8, learning_rate=0.1, random_state=42, eval_metric='logloss')\n",
    "elif 'LightGBM' in mejor_modelo_nombre:\n",
    "    mejor_modelo = lgb.LGBMClassifier(n_estimators=200, max_depth=15, random_state=42, verbose=-1)\n",
    "else:\n",
    "    mejor_modelo = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(f\"\\nReentrenando {mejor_modelo_nombre} con hiperpar√°metros optimizados...\")\n",
    "mejor_modelo.fit(X_train_balanced, y_train_balanced)\n",
    "print(\"‚úì Modelo reentrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluaci√≥n Final del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones finales\n",
    "y_pred_final = mejor_modelo.predict(X_test_scaled)\n",
    "y_pred_proba_final = mejor_modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUACI√ìN FINAL EN TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred_final, target_names=['Riesgo Bajo', 'Riesgo Alto']))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Bajo', 'Alto'], yticklabels=['Bajo', 'Alto'])\n",
    "axes[0].set_ylabel('Valor Real')\n",
    "axes[0].set_xlabel('Predicci√≥n')\n",
    "axes[0].set_title('Matriz de Confusi√≥n', fontweight='bold')\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_final)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Curva ROC', fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/ml_evaluacion_final.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: reports/figures/ml_evaluacion_final.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    importancias = pd.DataFrame({\n",
    "        'Feature': features_finales,\n",
    "        'Importance': mejor_modelo.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"TOP 10 FEATURES M√ÅS IMPORTANTES\")\n",
    "    print(\"=\" * 70)\n",
    "    print(importancias.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    top_n = 15\n",
    "    top_features = importancias.head(top_n)\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    \n",
    "    bars = ax.barh(y_pos, top_features['Importance'], alpha=0.8, color='steelblue')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_features['Feature'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Importancia')\n",
    "    ax.set_title(f'Top {top_n} Features M√°s Importantes', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores\n",
    "    for i, v in enumerate(top_features['Importance']):\n",
    "        ax.text(v + 0.001, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/ml_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Gr√°fico guardado: reports/figures/ml_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo y scaler\n",
    "joblib.dump(mejor_modelo, '../src/models/modelo_desercion.pkl')\n",
    "print(\"‚úì Guardado: src/models/modelo_desercion.pkl\")\n",
    "\n",
    "joblib.dump(scaler, '../src/models/scaler.pkl')\n",
    "print(\"‚úì Guardado: src/models/scaler.pkl\")\n",
    "\n",
    "# Guardar lista de features\n",
    "pd.DataFrame({'features': features_finales}).to_csv('../src/models/features.csv', index=False)\n",
    "print(\"‚úì Guardado: src/models/features.csv\")\n",
    "\n",
    "# Guardar m√©tricas\n",
    "metricas_finales = {\n",
    "    'modelo': mejor_modelo_nombre,\n",
    "    'accuracy': accuracy_score(y_test, y_pred_final),\n",
    "    'precision': precision_score(y_test, y_pred_final),\n",
    "    'recall': recall_score(y_test, y_pred_final),\n",
    "    'f1_score': f1_score(y_test, y_pred_final),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_final)\n",
    "}\n",
    "pd.DataFrame([metricas_finales]).to_csv('../src/models/metricas_modelo.csv', index=False)\n",
    "print(\"‚úì Guardado: src/models/metricas_modelo.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ MODELO GUARDADO EXITOSAMENTE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Funci√≥n de Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para hacer predicciones\n",
    "def predecir_riesgo(estudiante_data, modelo, scaler, features):\n",
    "    \"\"\"\n",
    "    Predice el riesgo de deserci√≥n de un estudiante\n",
    "    \n",
    "    Args:\n",
    "        estudiante_data: dict con caracter√≠sticas del estudiante\n",
    "        modelo: modelo entrenado\n",
    "        scaler: scaler ajustado\n",
    "        features: lista de features del modelo\n",
    "    \n",
    "    Returns:\n",
    "        dict con predicci√≥n y probabilidad\n",
    "    \"\"\"\n",
    "    # Crear DataFrame con features\n",
    "    df_pred = pd.DataFrame([estudiante_data])\n",
    "    \n",
    "    # Asegurar que tiene todas las features\n",
    "    for feat in features:\n",
    "        if feat not in df_pred.columns:\n",
    "            df_pred[feat] = 0\n",
    "    \n",
    "    df_pred = df_pred[features]\n",
    "    \n",
    "    # Escalar\n",
    "    X_scaled = scaler.transform(df_pred)\n",
    "    \n",
    "    # Predecir\n",
    "    prediccion = modelo.predict(X_scaled)[0]\n",
    "    probabilidad = modelo.predict_proba(X_scaled)[0, 1]\n",
    "    \n",
    "    # Clasificar nivel\n",
    "    if probabilidad < 0.3:\n",
    "        nivel = 'BAJO'\n",
    "    elif probabilidad < 0.5:\n",
    "        nivel = 'MEDIO'\n",
    "    elif probabilidad < 0.7:\n",
    "        nivel = 'ALTO'\n",
    "    else:\n",
    "        nivel = 'CRITICO'\n",
    "    \n",
    "    return {\n",
    "        'prediccion': int(prediccion),\n",
    "        'probabilidad': float(probabilidad),\n",
    "        'nivel_riesgo': nivel\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso\n",
    "ejemplo_estudiante = {\n",
    "    'edad': 22,\n",
    "    'estrato_num': 2,\n",
    "    'periodo_a√±o': 2024,\n",
    "    'periodo_semestre': 1,\n",
    "    'edad_fuera_rango': 0,\n",
    "    'es_virtual': 1,\n",
    "    'estrato_bajo': 1\n",
    "}\n",
    "\n",
    "resultado = predecir_riesgo(ejemplo_estudiante, mejor_modelo, scaler, features_finales)\n",
    "print(\"\\nEjemplo de Predicci√≥n:\")\n",
    "print(f\"Probabilidad de alto riesgo: {resultado['probabilidad']*100:.2f}%\")\n",
    "print(f\"Nivel de riesgo: {resultado['nivel_riesgo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN DEL MODELO PREDICTIVO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nü§ñ MODELO SELECCIONADO: {mejor_modelo_nombre}\")\n",
    "\n",
    "print(f\"\\nüìä M√âTRICAS EN TEST SET:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {metricas_finales['accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {metricas_finales['precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {metricas_finales['recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {metricas_finales['f1_score']:.4f}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC: {metricas_finales['roc_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ INTERPRETACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ El modelo detecta {metricas_finales['recall']*100:.1f}% de estudiantes en riesgo\")\n",
    "print(f\"   ‚Ä¢ {metricas_finales['precision']*100:.1f}% de predicciones positivas son correctas\")\n",
    "print(f\"   ‚Ä¢ Balance entre precision y recall: {metricas_finales['f1_score']:.4f}\")\n",
    "\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    top_3_features = importancias.head(3)['Feature'].tolist()\n",
    "    print(f\"\\nüîë TOP 3 FACTORES DE RIESGO:\")\n",
    "    for i, feat in enumerate(top_3_features, 1):\n",
    "        print(f\"   {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(f\"   ‚Ä¢ Modelo entrenado: src/models/modelo_desercion.pkl\")\n",
    "print(f\"   ‚Ä¢ Scaler: src/models/scaler.pkl\")\n",
    "print(f\"   ‚Ä¢ Features: src/models/features.csv\")\n",
    "print(f\"   ‚Ä¢ M√©tricas: src/models/metricas_modelo.csv\")\n",
    "\n",
    "print(f\"\\nüìà VISUALIZACIONES:\")\n",
    "print(f\"   ‚Ä¢ Comparaci√≥n de modelos\")\n",
    "print(f\"   ‚Ä¢ Matriz de confusi√≥n y curva ROC\")\n",
    "print(f\"   ‚Ä¢ Feature importance\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ MODELO PREDICTIVO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüéØ SIGUIENTE: Integrar modelo en dashboard o aplicaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fin del Notebook ML Model\n",
    "\n",
    "**Logros:**\n",
    "- ‚úÖ Feature engineering completo\n",
    "- ‚úÖ 6 modelos entrenados y comparados\n",
    "- ‚úÖ Mejor modelo seleccionado y optimizado\n",
    "- ‚úÖ M√©tricas de evaluaci√≥n completas\n",
    "- ‚úÖ Feature importance analizado\n",
    "- ‚úÖ Modelo guardado para producci√≥n\n",
    "- ‚úÖ Funci√≥n de predicci√≥n lista\n",
    "\n",
    "**Modelo listo para:**\n",
    "- üì± Integraci√≥n en dashboard\n",
    "- üåê API REST\n",
    "- üìä Sistema de alertas tempranas\n",
    "- üéì Aplicaci√≥n en producci√≥n\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
